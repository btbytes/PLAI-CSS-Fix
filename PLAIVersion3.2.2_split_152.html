<?xml version='1.0' encoding='utf-8'?>
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <title>Unknown</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link rel="stylesheet" type="text/css" href="stylesheet.css"/>
<link rel="stylesheet" type="text/css" href="page_styles.css"/>
</head>
  <body class="c">
<h2 class="c27" id="h.98lrgqdhs8f4"><span class="c4">Why Lazy Evaluation</span></h2><p class="c3"><span class="c4"></span></p><p class="c5"><span class="c4">Suppose, instead, we evaluate this lazily. The evaluation would look like this:</span></p><p class="c3"><span class="c4"></span></p><p class="c5"><span class="c41">  (f (+ 2 3))</span></p><p class="c5"><span class="c41">→ (g (+ (+ 2 3) (+ 2 3)))</span></p><p class="c5"><span class="c41">→ (h (* (+ (+ 2 3) (+ 2 3))) 2))</span></p><p class="c5"><span class="c41">→ (+ (* (+ (+ 2 3) (+ 2 3))) 2) 5)</span></p><p class="c3"><span class="c4"></span></p><p class="c5"><span class="c4">A natural question might be, why bother doing this? </span></p><p class="c3"><span class="c4"></span></p><ol class="c134" start="1"><li class="c135 pcalibre19"><span class="calibre3">A reason people often cite is that it can save time, in that we don’t need to evaluate parameters we don’t need. For instance, suppose we have<br class="calibre"/><br class="calibre"/></span><span class="c28">(deffun (f x y z)<br class="calibre"/>  (if (zero? x)<br class="calibre"/>      y<br class="calibre"/>      z))<br class="calibre"/><br class="calibre"/></span><span class="c4">and we call f with two expensive-to-compute parameters in the last two positions. In an eager language, we have evaluated both whether we want to or not. In a lazy language, we only evaluate the one we need. As we will see below, this is actually not a very compelling argument.<br class="calibre"/></span></li><li class="c135 pcalibre19"><span class="calibre3">A second reason is that it enables us to add new, non-eager constructs to the language through functions. Consider </span><span class="c28">if</span><span class="calibre3">: in an eager language it can’t be a function because the whole point of </span><span class="c28">if</span><span class="c4"> is to not evaluate one of the branches (which would become parameters that are evaluated). Again, this argument has somewhat limited merit: we have seen how we can add such constructs using macros, which can do a great deal more as well.<br class="calibre"/></span></li><li class="c135 pcalibre19"><span class="calibre3">The most interesting reason is probably that </span><span class="c7">the set of equations that govern the language changes</span><span class="calibre3">. Consider the following. Suppose we have the expressions </span><span class="c28">E</span><span class="calibre3"> and </span><span class="c28">(lambda (x) (E x))</span><span class="calibre3">. Are they the “same”? It would seem, intuitively, that they are. Suppose </span><span class="c28">E</span><span class="calibre3"> is a function. In any setting where we apply </span><span class="c28">E</span><span class="calibre3"> to a parameter, the second expression does exactly the same: it takes that parameter, binds it to </span><span class="c28">x</span><span class="calibre3">, and then applies </span><span class="c28">E</span><span class="calibre3"> to </span><span class="c28">x</span><span class="calibre3">, which has the same effect.<br class="calibre"/><br class="calibre"/>However, note that </span><span class="c28">E</span><span class="calibre3"> may not be a function! It could be a </span><span class="c28">print</span><span class="calibre3"> statement,</span><span class="c28"> (/ 1 0)</span><span class="calibre3">, and so on. In those cases, </span><span class="c28">E</span><span class="calibre3"> evaluates right away and has some observable effect, but the version “hidden under the </span><span class="c28">lambda</span><span class="c4">” will not until it is used.<br class="calibre"/><br class="calibre"/>Why does this matter? It matters because many parts of programming implementations and tools want to replace some terms with other terms. An optimizing compiler does this (replacing a term with an equivalent one that is better by whatever optimizing criterion is in use), as do program refactoring engines, and more. Thus, the more terms that can be replaced, or the fewer conditions under which terms can be replaced, the better. Lazy languages allow more terms to be replaced.</span></li></ol><p class="c3"><span class="c4"></span></p><p class="c31"><span class="c40">Terminology: </span><span class="c4">This equivalence is called “rule eta” (η).</span></p><p class="c51"><span class="c4"></span></p><p class="c31"><span class="c40">Terminology: </span><span class="calibre3">You may see some people say that lazy languages have “referential transparency”. If you ask them to define it, they may say something like “you can replace equals with equals”. Think about that for a moment: you can </span><span class="c7">always</span><span class="calibre3"> replace equals with equals. That is (by some definitions) literally what equality </span><span class="c7">means</span><span class="c4">: two things are equal exactly when you can replace one with the other. So that phrase tells us nothing. In fact, every language has some degree of “referential transparency”: you can always replace some things with other equivalent things. In lazy languages, the set of things you can replace is usually bigger: the referential transparency relation is larger. That’s all.<br class="calibre"/></span></p><ol class="c24" start="4"><li class="c135 pcalibre19"><span class="c4">One very important, practical reason is to create potentially-infinite data structures. See the example on streams below.<br class="calibre"/></span></li><li class="c135 pcalibre19"><span class="calibre3">More fundamentally, the famous paper </span><span class="c26"><a class="c11" href="https://www.google.com/url?q=https://www.cse.chalmers.se/~rjmh/Papers/whyfp.html&amp;sa=D&amp;source=editors&amp;ust=1695232021569949&amp;usg=AOvVaw13ypvMWgaZXeEPuILJzYCX">Why Functional Programming Matters</a></span><span class="calibre3"> argues that laziness is a </span><span class="c7">modularity</span><span class="c4"> concept, and develops this argument through several beautiful examples.</span></li></ol></body></html>
